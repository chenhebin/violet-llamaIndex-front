## ğŸ”¥ æ‘˜è¦
RAGï¼ˆæ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰ä½œä¸ºAIå·¥ç¨‹åŒ–çš„é‡è¦æŠ€æœ¯ï¼Œè€ŒAIå·¥ç¨‹åŒ–èƒ½åŠ›å°†æˆä¸ºæœªæ¥å‰ç«¯æ ¸å¿ƒç«äº‰åŠ›ï¼Œå…¶å¯¹å‰ç«¯å¼€å‘è€…å…·æœ‰ç‰¹æ®Šä»·å€¼ï¼š

1. **èƒ½åŠ›è¾¹ç•Œçªç ´**ï¼šé€šè¿‡LlamaIndexã€langChainç­‰è½»é‡æ¡†æ¶ï¼Œå‰ç«¯å¼€å‘è€…æ— éœ€æ·±åº¦å­¦ä¹ èƒŒæ™¯å³å¯å®ç°æœ¬åœ°çŸ¥è¯†é—®ç­”ç³»ç»Ÿå°†ä¼ ç»ŸUIå¼€å‘å»¶ä¼¸è‡³æ™ºèƒ½äº¤äº’é¢†åŸŸ

2. **å…¨æ ˆä»·å€¼æå‡**ï¼šå‰ç«¯å¯ç›´æ¥ç®¡ç†æ–‡æ¡£åŠ è½½->å‘é‡åŒ–->æŸ¥è¯¢çš„å®Œæ•´AIé“¾è·¯ï¼Œæ‰“ç ´å‰åç«¯æŠ€æœ¯å£å’ï¼ˆåç»­å»¶ä¼¸å¯åŸºäºnextæ–¹æ¡ˆï¼‰

3. **æ–°å‹åœºæ™¯è½åœ°**ï¼šåŸºäºæµè§ˆå™¨çš„æœ¬åœ°AIèƒ½åŠ›ï¼ˆå¦‚é¡¹ç›®ä¸­çš„Ollamaé›†æˆï¼‰ï¼Œå¯å¼€å‘ç¦»çº¿æ™ºèƒ½åŠ©æ‰‹ã€ç§æœ‰åŒ–çŸ¥è¯†åº“ç­‰åœºæ™¯ï¼Œç¬¦åˆGDPRæ—¶ä»£çš„æ•°æ®éšç§è¦æ±‚  

æˆ‘ä»¬è¿™ç¯‡æ–‡ç« ä»…ä»…åªæ˜¯åŸºäºjså’Œä¸šç•Œå·²æœ‰çš„ç¬¬ä¸‰æ–¹åº“ï¼Œæ­å»ºä¸€ä¸ªæœ€å°åŒ–çš„æœ¬åœ°æ¨¡å‹é—®ç­”çš„ragå¢å¼ºmvpï¼Œæ—¨åœ¨ä¸ºå¤§å®¶æä¾›ä¸€äº›æ€è·¯å’Œæ ·ä¾‹ï¼Œå¸Œæœ›èƒ½å¯¹å¤§å®¶è‡ªå·±å¿ƒä¸­æƒ³åšçš„äº‹æƒ…ä¸€ç‚¹å¸®åŠ©ã€‚  

## ğŸ‰ æ¶æ„é¢„è§ˆ
![image.png](./img/rag.png)

## ğŸŒŸ æ•ˆæœé¢„è§ˆ
åœ¨ç»ˆç«¯ä¸­è¿è¡Œé—®ç­”ï¼Œé€šè¿‡è‡ªç„¶è¯­è¨€æé—®ï¼ˆå¦‚"violetå‡ å²äº†ï¼Ÿä»–çˆ±åƒä»€ä¹ˆï¼Ÿ"ï¼‰ï¼Œç³»ç»Ÿèƒ½ä»æœ¬åœ°çŸ¥è¯†åº“ï¼ˆknowledge1.txtï¼‰ä¸­æ£€ç´¢å¹¶ç”Ÿæˆå‡†ç¡®å›ç­”ï¼š

```bash
ğŸ§  å›ç­”ç”Ÿæˆä¸­...
ğŸ§  å›ç­”ï¼š violetå·²ç»24å²äº†ï¼Œå–œæ¬¢åƒè‚¯å¾·åŸºçš„å®æŒ‡åŸå‘³é¸¡ã€‚
```

## ğŸ› ï¸ ç¯å¢ƒå‡†å¤‡
1. å®‰è£…åŸºç¡€ç¯å¢ƒï¼š
```bash
# Node.jsï¼ˆå»ºè®®18+ç‰ˆæœ¬ï¼‰
brew install node 

```

2. æœ¬åœ°ä¸‹è½½ollamaï¼šhttps://ollama.com/download  

3. ä¸‹è½½NLPæ¨¡å‹ï¼š
```bash
# ä¸‹è½½7Bå¤§è¯­è¨€æ¨¡å‹
ollama pull deepseek-r1:7b

# ä¸‹è½½æ–‡æœ¬åµŒå…¥æ¨¡å‹
ollama pull nomic-embed-text
```

## ğŸš€ é¡¹ç›®åˆå§‹åŒ–
1. åˆ›å»ºé¡¹ç›®ç›®å½•ï¼š
```bash
mkdir violet-llamaIndex-front
npm init -y
```

2. å®‰è£…æ ¸å¿ƒä¾èµ–ï¼š
```bash
npm install llamaindex @llamaindex/ollama @llamaindex/readers
```

## ğŸ“‚ æ ¸å¿ƒä»£ç è§£æ
### 1. é—®ç­”å…¥å£ï¼ˆsrc/index.jsï¼‰
<mcsymbol name="index.js" filename="index.js" path="/Users/chenhebin/Documents/violet/code/ai/llamaIndex/violet-llamaIndex-front/src/index.js" startline="1" type="function"></mcsymbol>
```javascript
import { storeVectors } from './ragHook/useVectorIndex.js'
import { queryVectors } from './ragHook/useQueryEngine.js'

// åˆ›å»ºå‘é‡ç´¢å¼•ï¼ˆåªéœ€è¦é¦–æ¬¡è¿è¡Œæ‰§è¡Œï¼Œè¿™è¾¹demoç›´æ¥è¿è¡Œï¼‰
await storeVectors()

// æ‰§è¡Œè‡ªç„¶è¯­è¨€é—®ç­”
await queryVectors('violetå‡ å²äº†ï¼Ÿä»–çˆ±åƒä»€ä¹ˆï¼Ÿ')
```

### 2. é…ç½®ç®¡ç†ï¼ˆollama.config.jsï¼‰
```javascript
// ollamaçš„é…ç½®ä¿¡æ¯
export const OLLAMA_CONFIG = {
    BASE_URL: "http://localhost:11434", // æœ¬åœ°OllamaæœåŠ¡åœ°å€
    // æœ¬åœ°OllamaæœåŠ¡ -ã€LLMæ¨¡å‹ã€‘
    LLM: {
        model: "deepseek-r1:7b",
        temperature: 0.5, // å¯é€‰å‚æ•°æ§åˆ¶ç”Ÿæˆéšæœºæ€§
        requestTimeout: 30000 // è¶…æ—¶è®¾ç½®ï¼ˆæ¯«ç§’ï¼‰
    },
    // æœ¬åœ°OllamaæœåŠ¡ -ã€åµŒå…¥æ¨¡å‹ã€‘
    EMBEDDING: {
        model: "nomic-embed-text",
        embeddingDimensions: 768 // å¿…é¡»ä¸æ¨¡å‹å®é™…ç»´åº¦åŒ¹é…
    }
};

// æœ¬åœ°å‘é‡å­˜å‚¨çš„é…ç½®ä¿¡æ¯
export const STORAGE_CONFIG = {
    PERSIST_DIR: "storage/ragTest"
};

// RAGçŸ¥è¯†åº“çš„é…ç½®ä¿¡æ¯
export const RAG_KNOWLEDGE_CONFIG = {
    KNOWLEDGE_PATH: "ragKnowledge"
}
```

## ğŸ§© å®ç°ç»†èŠ‚
### æ–‡æ¡£å‘é‡åŒ–æµç¨‹
```javascript
// å…ˆåˆå§‹åŒ–å…¨å±€è®¾ç½®
Settings.embedModel = initializeEmbedding()

/**
 * ä»æœ¬åœ°ç›®å½•ä¸­åŠ è½½æ–‡æ¡£å¹¶åˆ›å»ºå‘é‡ç´¢å¼•å‚¨å­˜åœ¨ç‰¹å®šçš„ä½ç½®
 * æ³¨æ„ï¼šè¿™é‡Œçš„queryEngineæ˜¯ä¸€ä¸ªå¼‚æ­¥å‡½æ•°ï¼Œéœ€è¦ç­‰å¾…è¿”å›ç»“æœåæ‰èƒ½ç»§ç»­æ‰§è¡Œåç»­ä»£ç 
 * å¯ä»¥ä½¿ç”¨async/awaitæˆ–è€….then()æ¥å¤„ç†è¿”å›çš„Promiseå¯¹è±¡
 */
export async function storeVectors() {
    // åˆ›å»ºå‘é‡å­˜å‚¨ç´¢å¼•
    const storageContext = await getStorageContext()
    // ä»ç›®å½•ä¸­åŠ è½½æ–‡æ¡£å¹¶è®¾ç½®å…ƒæ•°æ®
    const documents = await getDocuments()

    // ä»æ–‡æ¡£ä¸­åˆ›å»ºå‘é‡ç´¢å¼•
    await VectorStoreIndex.fromDocuments(documents, {
        serviceContext: {
            embedModel: Settings.embedModel // ä½¿ç”¨å…¨å±€è®¾ç½®çš„åµŒå…¥æ¨¡å‹ï¼ˆæœ¬åœ°ollamaæ¨¡å‹ï¼‰
        },
        storageContext
    })
    console.log('-----ç´¢å¼•åˆ›å»ºå®Œæˆ-----');
}
```

### å‘é‡ç´¢å¼•æ„å»º
```javascript
// åˆå§‹åŒ–å…¨å±€è®¾ç½® - llamaindexåº•å±‚ä¼šè‡ªåŠ¨ä½¿ç”¨Settings.llmå’ŒSettings.embedModelçš„é…ç½®ï¼Œä¸ç”¨æ‰‹åŠ¨æ³¨å…¥
Settings.llm = initializeLLM();
Settings.embedModel = initializeEmbedding();

/**
 * ä»æœ¬åœ°å‘é‡åº“ä¸­æŸ¥è¯¢å¹¶ç”Ÿæˆå›ç­”
 * æ³¨æ„ï¼šè¿™é‡Œçš„queryEngineæ˜¯ä¸€ä¸ªå¼‚æ­¥å‡½æ•°ï¼Œéœ€è¦ç­‰å¾…è¿”å›ç»“æœåæ‰èƒ½ç»§ç»­æ‰§è¡Œåç»­ä»£ç 
 * å¯ä»¥ä½¿ç”¨async/awaitæˆ–è€….then()æ¥å¤„ç†è¿”å›çš„Promiseå¯¹è±¡
 * @param {*} question 
 * @returns 
 */
export async function queryVectors(question) {
    // åŸºäºå·²ç»å®ŒæˆæŒä¹…åŒ–çš„ç›®å½•ï¼Œåˆ›å»ºå‘é‡å­˜å‚¨ç´¢å¼•-ã€storageContextFromDefaultsæ–¹æ³•ã€‘
    const storageContext = await getStorageContext();
    // åŸºäºå‘é‡å­˜å‚¨ç´¢å¼•ï¼Œåˆå§‹åŒ–åˆ›å»ºæŸ¥è¯¢å¼•æ“
    const index = await VectorStoreIndex.init({ storageContext });
    // åˆ›å»ºæŸ¥è¯¢å¼•æ“
    const queryEngine = index.asQueryEngine();

    console.log("ğŸ§  å›ç­”ç”Ÿæˆä¸­...");
    // å‘èµ·æŸ¥è¯¢ï¼Œå¯ä»¥ä½¿ç”¨æµå¼å¤„ç†ã€stram: trueã€‘ï¼Œä½†æ˜¯éœ€è¦é¢å¤–å¤„ç†æµå¼æ•°æ®
    const response = await queryEngine.query({ query: question });
    console.log("ğŸ§  å›ç­”ï¼š", response.toString());
    return response;
}

```

## ğŸ” å¸¸è§é—®é¢˜æ’æŸ¥
1. æœåŠ¡å¯åŠ¨å¤±è´¥æ£€æŸ¥ï¼š
```bash
# ç¡®è®¤OllamaæœåŠ¡çŠ¶æ€
lsof -i :11434

# æ£€æŸ¥æ¨¡å‹ä¸‹è½½çŠ¶æ€
ollama list

# æ£€æŸ¥æ¨¡å‹è¿è¡Œæƒ…å†µ
ollama ps
```

2. ç´¢å¼•æ„å»ºé—®é¢˜ï¼š
```bash
# æŸ¥çœ‹å­˜å‚¨ç›®å½•ç»“æ„
ls -l storage/ragTest/
```

## ğŸ“š å­¦ä¹ èµ„æº
- LlamaIndexå®˜æ–¹æ–‡æ¡£ï¼šhttps://ts.llamaindex.ai/
- Ollamaæ¨¡å‹åº“ï¼šhttps://ollama.com/library

å¸Œæœ›è¿™ä»½æ•™ç¨‹èƒ½å¸®åŠ©å¤§å®¶å¿«é€Ÿæ­å»ºæœ¬åœ°çŸ¥è¯†é—®ç­”demoï¼Œå¦‚æœ‰å…¶ä»–å®ç°ç»†èŠ‚éœ€è¦å±•å¼€è®²è§£ï¼Œæ¬¢è¿åœ¨è¯„è®ºåŒºäº¤æµè®¨è®º~